* 微服务

** 单体服务拆分为微服务的方案

  - 按照业务纵向拆分，每个独立的业务单独一个服务；
  - 按照代码功能维度，横向进行拆分，每个独立的功能一个服务；
  - 人员聚类，这是个实际中的考量，如果某几个业务就是这几个人比较熟，那么最好放在一起，未来开发部署都好办;
  - 性能聚类，性能要求高的并发大的和性能要求低的并发小的，要分开为不同的服务，这样部署和运行都独立，好维护;
    

** 微服务架构下，服务调用主要依赖的基本组件
   
  - 服务描述
  - 注册中心
  - 服务框架
  - 服务监控
  - 服务追踪
  - 服务治理
    

*** 服务描述

    服务调用首先要解决的问题就是服务如何对外描述。如：
    + 服务名是什么；
    + 调用这个服务需要提供哪些信息；
    + 服务调用返回的结果是什么格式；
    + 如何解析服务调用返回的结果；

    常用的服务描述方式
    + RESTful API  --  常用于 HTTP 协议的服务描述；
    + XML 配置  --  常用作 RPC 协议的服务描述；
    + IDL(interface description language) 文件  --  通常用作 Thrift 和 gRPC 这类跨语言服务调用框架；
      - gRPC 协议使用 Protobuf 简称 proto 文件来定义接口名、调用参数以及返回值类型；
      

*** 注册中心
    
    解决服务的发布和订阅，服务提供者将自己提供的服务以及地址登记到注册中心，服务的消费者从注册中心查询所需要
    调用的服务的地址，然后发起请求。
    
    注册中心的工作流程为：
    + 服务提供者在启动时，根据服务发布文件中配置的发布信息向注册中心注册自己的服务；
    + 服务消费者在启动时，根据消费者配置文件中配置的服务信息向注册中心订阅自己所需要的服务；
    + 注册中心返回服务提供者地址列表给服务消费者；
    + 当服务提供者发生变化，比如有节点新增或者销毁，注册中心将变更通知给服务消费者；
      

*** 服务框架

    对于微服务的架构，需要考虑如下问题：
    + 服务通信采用什么协议？即服务提供者和服务消费者之间以什么样的协议进行网络通信，是采用四层 TCP、UDP 协议，
      还是七层 HTTP 协议，还是采用其他协议？
    + 数据传输采用什么方式？即服务提供者和服务消费者之间的数据传输采用哪种方式，是同步还是异步，是在单连接上传输，
      还是多路复用？
    + 数据压缩采用什么格式？通常数据传输都会对数据进行压缩，以减少网络传输的数据量，从而减少带宽消耗和网络传输
      时间，比如常见的 JSON 序列化，Java 对象序列化以及 Protobuf 序列化。


*** 服务监控

    当服务消费者与服务提供者之间能够正常发起服务调用后，需要对调用情况进行监控，包括：
    + 指标收集。就是把每一次服务调用的请求耗时以及成功与否收集起来，并上传到集中的数据处理中心；
    + 数据处理。有了上面的每次调用的请求耗时以及成功与否等信息，就可以计算每秒服务请求量、平均耗时以及成功率等指标；
    + 数据展示。需要将上面处理好的数据在 dashboard 上展示出来。
      

*** 服务追踪

    除了要对服务调用情况进行监控外，还需要记录服务调用经过的每一层链路，以便进行问题追踪和故障定位。

    服务追踪的工作原理大致如下：
    + 服务消费者发起调用前，会在本地按照一定的规则生成一个 requestid，发起调用时，将 requestid 当作请求参数的一部分，
      传递给服务提供者；
    + 服务提供者接收到请求后，记录下这次请求的 requestid，然后处理请求。如果服务提供者继续请求其他服务，会在本地再生成
      一个自己的 requestid，然后把这两个 requestid 都当做请求参数继续往下传递。
      
    最后，无论依赖多少次服务调用、经过多少服务节点，都可以通过最开始生成的 requestid 串联所有节点，从而达到服务追踪的目的。
    

*** 服务治理

    服务监控发现问题，服务追踪定位问题，服务治理解决问题。
    
    服务治理就是通过一系列的手段来保证在各种意外情况下，服务调用仍然能够正常进行。

    

* Istio

** Deploy Istio
   
    Istio 的部署流程主要分为两部分

    - 第一部分包括安装 CLI 工具，主要用来部署和管理 Istio 后端服务；
    - 第二部分为配置 Kubernetes 集群以支持 Istio;
      

*** Install CLI tooling
    
     执行如下命令以安装 Istio 1.0.0 release 版本
     #+BEGIN_SRC sh
     curl -L https://git.io/getLatestIstio | ISTIO_VERSION=1.0.0 sh -
     #+END_SRC
     
     增加 bin 目录到 PATH 环境变量中
     
     #+BEGIN_SRC sh
     export PATH="$PATH:/root/istio-1.0.0/bin"
     cd /root/istio-1.0.0
     #+END_SRC
     

*** Configure Istio CRD
    
     Istio 通过 CRD (Custom Resource Definitions) 实现了针对 Kubernetes 的扩展，
     通过 applying crds.yaml 来部署扩展
     
     #+BEGIN_SRC sh
     kubectl apply -f install/kubernetes/helm/istio/templates/crds.yaml -n istio-system
     #+END_SRC
     
      
*** Install Istio with default mutual TLS authentication
    
     使用 istio-demo-auth.yaml 来安装 Istio 并默认启用 mutual TLS 验证
     
     #+BEGIN_SRC sh
     kubectl apply -f install/kubernetes/istio-demo-auth.yaml
     #+END_SRC
     
     这将会部署 Pilot, Mixer, Ingress-Controller, Egress-Controller 和 Istio CA
     (Certificate Authority)
     

*** Check Status
    
     #+BEGIN_SRC sh
     kubectl get pods -n istio-system
     #+END_SRC
     
     直到所有 pods 状态均为 running 或是 completed
     

*** Deploy Katacoda Service
    
     #+BEGIN_SRC sh
     kubectl apply -f /root/katacoda.yaml
     service/katacoda-servicegraph created
     service/katacoda-grafana created
     service/katacoda-jaeger-query created
     service/katacoda-prometheus created
     service/istio-ingressgateway configured
     #+END_SRC
     
     可以通过

     #+BEGIN_SRC sh
     kubectl get svc -n istio-system
     #+END_SRC
     
     来查看当前启动的所有服务
     

** Istio Architecture
   
    - Pilot 
      + Responsible for configuring the Envoy and Mixer at runtime.
      + 即负责运行时对 Envoy 和 Mixer 进行配置
        
    - Proxy/Envoy
      + Sidecar proxies per microservice to handle ingress/egress 
        traffic between services in the cluster and from a service 
        to external services. The proxies form a secure microservice 
        mesh providing a rich set of functions like discovery, rich 
        layer-7 routing, circuit breakers, policy enforcement and 
        telemetry recording/reporting functions.
      + 主要用于处理微服务网格中各服务之间通信的
        
    - Mixer
      + Create a portability layer on top of infrastructure backends. 
        Enforce policies such as ACLs, rate limits, quotas, authentication, 
        request tracing and telemetry collection at an infrastructure level.
      + 在后端基础架构之上增加的一层可移植层，实现了在基础架构一层对 ACLs, rate limits,
        quotas, authentication, request tracing 和 telemetry collection 等
        策略进行执行；
        
    - Citadel / Istio CA
      + Secures service to service communication over TLS. Providing a key 
        management system to automate key and certificate generation, 
        distribution, rotation, and revocation.
      + 主要用于身份认证等安全机制

    - Ingress/Egress
      + Configure path based routing for inbound and outbound external traffic.
      + 主要用于微服务的出入流量管理
        
    - Control Plane API
      + Underlying Orchestrator such as Kubernetes or Hashicorp Nomad.
      + 控制平面 API
        

    整体的系统架构如下

    /Users/vampirem/Good_Study/Istio_overall_architectur.png
    

** Deploy Sample Application
   
    当部署一个将要通过 Istio 进行扩展的应用时，Kubernetes YAML 定义文件需要通过
    kube-inject 来进行扩展。如

    #+BEGIN_SRC sh
    kubectl apply -f <(istioctl kube-inject -f samples/bookinfo/platform/kube/bookinfo.yaml)
    #+END_SRC
    

** Control Routing
   
     Istio 的重要特性之一是流量管理。作为一个微服务架构的温标，需要具备对
     服务到服务的流量控制特性。
     
*** User Based Testing/Request Routing
    
      流量管理的一方面是基于 HTTP 请求，如 user agent strings, IP 地址
      以及 cookies 等来进行流量路由的控制；
      

*** Traffic Shaping for Canary Releases
    
      通过对访问流量进行切分，来实现金丝雀发布
      

** Istio 中比较常用的 dashboard 可视化工具

     - grafana

       + 返回当前正在被处理的所有请求的数量；
       + 发生错误的数量
       + 每个调用请求的应答时间；

     - Jaeger
       
       + 对每一个 HTTP 请求进行追踪；
       + 展示调用了什么；
       + 请求处理的时间都花费在哪里；
         
     - Service Graph
       
       + 展示 Istio 系统中各服务连接的依赖树状图

     - Weave Scope
       
       + Service Graph 从一个较高的层次展示了系统中各服务连接的概况；而 Weave Scope
         则提供了一个非常好的视图概览以及针对整个集群的 debug 工具；
         
       + 使用 Scope 能够观察到每个 Pod 中都有哪些进程在运行，以及 Pods 之间的彼此
         连接情况;
         
       部署 Weave Scope

       #+BEGIN_SRC sh
       kubectl create -f 'https://cloud.weave.works/launch/k8s/weavescope.yaml
       #+END_SRC
       
       对外暴露 Weave Scope 服务，使得 Scope 可访问
       
       #+BEGIN_SRC sh
       pod=$(kubectl get pod -n weave --selector=name=weave-scope-app -o jsonpath={.items..metadata.name})
       kubectl expose pod $pod -n weave --external-ip="172.17.0.44" --port=4040 --target-port=4040
       #+END_SRC


** 常用场景

   + 服务熔断 -- 软件系统中，由于某些原因使得服务出现过载现象，为防止造成整个系统故障，从而采用
               一种保护措施，因此服务熔断实际上就是过载保护。
               
   + 服务降级 -- 系统整体资源不够用时，将某些服务先关掉，待资源充足时，再重启回来。
